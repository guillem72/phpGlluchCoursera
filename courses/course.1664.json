{
    "id": 1664,
    "shortName": "ntumltwo",
    "name": "機器學習技法 (Machine Learning Techniques)",
    "language": "zh-tw",
    "shortDescription": "The course extends the fundamental tools in \"Machine Learning Foundations\" to powerful and practical models by three directions, which includes embedding numerous features, combining predictive features, and distilling hidden features. [這門課將先前「機器學習基石」課程中所學的基礎工具往三個方向延伸為強大而實用的工具。這三個方向包括嵌入大量的特徵、融合預測性的特徵、與萃取潛藏的特徵。]",
    "aboutTheCourse": "Welcome! The instructor has decided to teach the course in Mandarin on \nCoursera, while the slides of the course will be in English to ease the \ntechnical illustrations. We \nhope that this choice can help introduce Machine Learning to more students in the Mandarin-speaking world. The English-written slides \nwill not require advanced English ability to understand, though. If you \ncan understand the following descriptions of this course, you can \nprobably follow the slides. <b>[歡迎大家！這門課將採用英文投影片配合華文的教學講解，我們希望能藉這次華文教學的機會，將機器學習介紹給更多華人世界的同學們。課程中使用的英文投影片不會使用到艱深的英文，如果你能了解以下兩段的課程簡介，你應該也可以了解課程所使用的英文投影片。]<\/b><br><br>In the prequel of this course, <span><a target=\"_blank\" href=\"https:\/\/www.coursera.org\/course\/ntumlone\"><i>Machine Learning Foundations<\/i><\/a>, we have illustrated<\/span> the necessary fundamentals that give any student of machine learning a \nsolid foundation to explore further techniques. While many new techniques are being designed every day, some techniques stood the test of time and became popular tools nowadays. <br><br>The course roughly corresponds to the second \nhalf-semester of the National Taiwan University course \"Machine \nLearning.\" Based \non five years of teaching this popular course successfully (including \nwinning the most prestigious teaching award of National Taiwan \nUniversity) and discussing with many other scholars actively, the \ninstructor chooses to focus on three of those popular tools, namely embedding numerous features (kernel models, such as support vector machine), combining predictive features (aggregation models, such as adaptive boosting), and distilling hidden features (extraction models, such as deep learning). <br><br><br>",
    "targetAudience": 1,
    "courseSyllabus": "<span>Each of the following items correspond to approximately one hour of video lecture.<b> [以下的每個小項目對應到約一小時的線上課程]<\/b><br><br>Embedding Numerous Features <b>[嵌入大量的特徵]<\/b><br>   -- Linear Support Vector Machine <b>[線性支持向量機]<\/b><br>   -- Dual Support Vector Machine <b>[對偶支持向量機]<\/b><br>   -- Kernel Support Vector Machine <b>[核型支持向量機]<\/b><br>   <\/span><span>-- Soft-Margin Support Vector Machine <b>[軟式支持向量機]<\/b><br>   <\/span><span><span>-- Kernel Logistic Regression <b>[核型羅吉斯迴歸]<\/b><br>-- Support Vector Regression<\/span> <b>[支持向量迴歸]<\/b><\/span><br><span><span><br>Combining Predictive Features <b>[融合預測性的特徵]<\/b><br>   -- Bootstrap Aggregation <b>[自助聚合法]<\/b><br>   -- Adaptive Boosting <b>[漸次提昇法]<\/b><br>   -- Decision Tree <b>[決策樹]<\/b><br>   <\/span><span>-- Random Forest <b>[隨機森林]<\/b><br>   <\/span><span>-- Gradient Boosted Decision Tree <b>[梯度提昇決策樹]<\/b><br><\/span><\/span><br>Distilling Hidden<span> Features <b>[萃取隱藏的特徵]<\/b><br>   -- Neural Network <b>[類神經網路]<\/b><br>   -- Deep Learning <b>[深度學習]<\/b><br>-- Radial Basis Function Network <\/span><b>[<\/b><span><b>逕向基函數網路]<\/b>   <br>-- Matrix Factorization <b>[矩陣分解]<\/b><br>   <\/span><br><span>Summary <b>[總結]<\/b><\/span><br><br>",
    "estimatedClassWorkload": "8-24 hours\/week",
    "recommendedBackground": "The basic knowledge on Calculus (differentiation), Linear Algebra (vector and matrix operations) and Probability (independent and dependent events) will be helpful. Some homeworks will require writing simple code so some programming background (on any platform) is recommended. We assume that the students have taken the NTU-Coursera \"Machine Learning Foundations\" class or equivalent. <b>[我們希望修課的同學對於基本的微分、向量與矩陣運算、及機率的工具有所了解。有些作業會需要寫作或執行一些程式，所以我們建議修課的同學能在你所熟悉的平台上有一些程式寫作的背景。我們假設修課的同學們已經學過「機器學習基石」或同等課程。]<\/b><br>",
    "links": {}
}