{
    "id": 7,
    "shortName": "nlp",
    "name": "Natural Language Processing",
    "language": "en",
    "shortDescription": "In this class, you will learn fundamental algorithms and mathematical models for processing natural language, and how these can be used to solve practical problems.",
    "aboutTheCourse": "<p>This course covers a broad range of topics in natural language processing, including word and sentence tokenization, text classification and sentiment analysis, spelling correction, information extraction, parsing, meaning extraction, and question answering, We will also introduce the underlying theory from probability, statistics, and machine learning that are crucial for the field, and cover fundamental algorithms like n-gram language modeling, naive bayes and maxent classifiers, sequence models like Hidden Markov Models, probabilistic dependency and constituent parsing, and vector-space models of meaning.<\/p>\nWe are offering this course on Natural Language Processing free and online to students worldwide, continuing Stanford's exciting forays into large scale online instruction. Students have access to screencast lecture videos, are given quiz questions, assignments and exams, receive regular feedback on progress, and can participate in a discussion forum. Those who successfully complete the course will receive a statement of accomplishment. Taught by Professors Jurafsky and Manning, the curriculum draws from Stanford's courses in Natural Language Processing. You will need a decent internet connection for accessing course materials, but should be able to watch the videos on your smartphone.&nbsp;<br><br>\n<p><strong>&nbsp;<\/strong><\/p>",
    "targetAudience": 1,
    "courseSyllabus": "<p>The following topics will be covered in the first two weeks:<\/p>\n<ol>\n<li><b>Introduction and Overview:<\/b><\/li>\n<li><b>Basic Text Processing:&nbsp;<\/b>J+M Chapters 2.1, 3.9; MR+S Chapters 2.1-2.2<\/li>\n<li><b>Minimum Edit Distance:&nbsp;<\/b>J+M Chapter 3.11<\/li>\n<li><b>Language Modeling:&nbsp;<\/b>J+M Chapter 4<\/li>\n<li><b>Spelling Correction:<\/b>&nbsp;J+M Chapters 5.9,&nbsp;<a href=\"http:\/\/norvig.com\/spell-correct.html\">Peter Norvig (2007) How to Write a Spelling Corrector<\/a><\/li>\n<\/ol>\n<div class=\"coursera-course-faq\"><\/div>",
    "estimatedClassWorkload": "8-10 hours\/week",
    "recommendedBackground": "<p>No background in natural language processing is required. Students will be expected to know a bit of basic probability (know Bayes rule), a bit about vectors and vector spaces (could length normalize a vector), a bit of calculus (know that the derivative of a function is zero at a maximum or minimum of a function), but we will review these concepts as we first use them. You should have reasonable programming ability (know about hash tables and graph data structures), be able to write programs in Java or Python, and have a computer (Windows, Mac or Linux) with internet access.<\/p>\n<p><\/p>",
    "links": {

    }
}